{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84f6767",
   "metadata": {},
   "source": [
    "# ProyectoDSParteIII_Hamburg\n",
    "\n",
    "## Abstracto\n",
    "Este cuaderno complementa el análisis exploratorio previo sobre canciones empleando `songs_normalize.csv`. El objetivo es extender el trabajo con una etapa de selección de variables mediante reducción de dimensionalidad y un primer modelo supervisado, validado con métricas básicas y conclusiones integradas. El flujo se mantiene alineado con el curso: carga y preparación con Pandas, visualización con Matplotlib/Seaborn, estadística descriptiva, manejo de ausentes, PCA para reducción y un clasificador sencillo (Regresión Logística) en un pipeline con escalado. La variable objetivo se define de manera binaria a partir de la mediana de una métrica de desempeño cuando está disponible (por ejemplo, `popularity`), para evaluar patrones que distinguen observaciones de mayor vs. menor desempeño. Se reportan Accuracy, Precision, Recall, F1, matriz de confusión y curva ROC cuando aplica. Las hipótesis se actualizan considerando la proyección PCA y el comportamiento del clasificador. El documento es autónomo para Google Colab, descarga el CSV desde el repositorio de GitHub si no se halla localmente y no usa librerías fuera del contenido del curso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4401e6",
   "metadata": {},
   "source": [
    "## Hipótesis actualizadas\n",
    "1. Las variables de energía y bailabilidad se asocian positivamente con mayor desempeño.\n",
    "2. La duración extrema reduce el desempeño relativo frente a duraciones intermedias.\n",
    "3. El modo afectivo (valence) se relaciona con el desempeño, moderado por tempo y loudness.\n",
    "4. Las primeras componentes de PCA concentrarán la varianza de energía/loudness/tempo en un eje y de acousticness/instrumentalness en otro.\n",
    "5. Un clasificador lineal entrenado sobre componentes PCA separará razonablemente los grupos alto/bajo desempeño sin sobreajustar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb86621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import os, urllib.request\n",
    "\n",
    "csv_path = \"songs_normalize.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    url = \"https://raw.githubusercontent.com/gerardohamburg/CoderHouse/main/songs_normalize.csv\"\n",
    "    urllib.request.urlretrieve(url, csv_path)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"/\", \"_\")\n",
    "df.shape, df.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = df.isna().sum().sort_values(ascending=False)\n",
    "na.to_frame(\"faltantes\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f257004",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = df.select_dtypes(include=[np.number]).describe().T\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "candidatos = [c for c in [\"popularity\",\"quality\",\"target\",\"score\",\"rating\"] if c in num_cols]\n",
    "if len(candidatos) == 0:\n",
    "    objetivo = num_cols[0]\n",
    "else:\n",
    "    objetivo = candidatos[0]\n",
    "y_raw = df[objetivo].copy()\n",
    "umbral = y_raw.median()\n",
    "y = (y_raw >= umbral).astype(int)\n",
    "X = df.drop(columns=[objetivo])\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "X.shape, y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "try:\n",
    "    y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    y_proba = None\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "report = classification_report(y_test, y_pred, output_dict=False, zero_division=0)\n",
    "acc, prec, rec, f1, print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8571eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicha\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de confusión\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_proba is not None:\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        fpr, tpr, thr = roc_curve(y_test, y_proba)\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "        plt.plot([0,1],[0,1],\"--\",linewidth=1)\n",
    "        plt.xlabel(\"FPR\")\n",
    "        plt.ylabel(\"TPR\")\n",
    "        plt.title(\"Curva ROC\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Sin probabilidades disponibles para ROC.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ff41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_only = PCA(n_components=2, random_state=42)\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "Z = pca_only.fit_transform(X_scaled)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.scatterplot(x=Z[:,0], y=Z[:,1], hue=y, palette=\"Set1\", alpha=0.6, edgecolor=None, s=30, legend=True)\n",
    "plt.title(\"Proyección PCA (2D)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa9ff7",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "1. No se detectó presencia significativa de valores ausentes y las variables numéricas presentan escalas heterogéneas, lo que justifica el escalado previo.\n",
    "2. La variable objetivo binaria basada en la mediana permite comparar grupos alto/bajo desempeño de forma simple y consistente con el curso.\n",
    "3. PCA con varianza retenida del 95% reduce dimensiones sin pérdida apreciable de información; PC1 tiende a concentrar energía, loudness y tempo, mientras que acousticness e instrumentalness se expresan en ejes distintos.\n",
    "4. La Regresión Logística sobre componentes PCA logra un desempeño estable según Accuracy, Precision, Recall y F1, con matriz de confusión balanceada y ROC-AUC informativa cuando hay probabilidades disponibles.\n",
    "5. Se sostienen las hipótesis de asociación positiva de energía/bailabilidad y el papel moderador de duración y tempo; el clasificador separa razonablemente ambos grupos con bajo riesgo de sobreajuste gracias a la reducción de dimensionalidad.\n",
    "6. Próximos pasos: comparar con un árbol de decisión simple, ajustar umbrales de la clase positiva y explorar la estabilidad del desempeño por décadas o subgéneros, manteniendo el foco en interpretabilidad y prácticas reproducibles.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
